# ğŸ’¡ Shape-Selective Splatting: Regularizing the Shape of Gaussian for Sparse-View Rendering

This repository provides the official PyTorch implementation of the paper:  
**[Shape-Selective Splatting: Regularizing the Shape of Gaussian for Sparse-View Rendering](https://ieeexplore.ieee.org/document/11119067?source=authoralert)**

by **Gun Ryu** and **Wonjun Kim (Corresponding Author)**  

ğŸ“„ *IEEE Signal Processing Letters (SPL), 2025*

---

## ğŸ“¦ Installation

### ğŸ›  Environment Setup

Install the required dependencies via conda:

```bash
conda env create -f environment.yml
conda activate sss
```


### ğŸ—‚ï¸ Dataset preparation
In the data preparation stage, we first reconstruct sparse-view inputs using **Structure-from-Motion (SfM)** with the provided camera poses from the datasets. Then, we perform dense stereo matching using COLMAPâ€™s `patch_match_stereo` function, followed by `stereo_fusion` to generate the dense stereo point cloud.

<details>
<summary><strong> Setup Instructions</strong></summary>

```bash
mkdir dataset
cd dataset

# Download LLFF dataset
gdown 16VnMcF1KJYxN9QId6TClMsZRahHNMW5g

# Generate sparse point cloud using COLMAP (limited views) for LLFF
python tools/colmap_llff.py

# Download MipNeRF-360 dataset
wget http://storage.googleapis.com/gresearch/refraw360/360_v2.zip
unzip -d mipnerf360 360_v2.zip

# Generate sparse point cloud using COLMAP (limited views) for MipNeRF-360
python tools/colmap_360.py
```

We also provide preprocessed sparse and dense point clouds for convenience.
You can download them via the link below:

ğŸ‘‰ [Download Preprocessed Point Clouds](https://drive.google.com/drive/folders/1P3I9m_HU0jF50qwxIIhXhegOVk-kihdI?usp=sharing)
</details>

Furthermore, we estimate monocular depth using the method described in [Fine-Tuning Image-Conditional Diffusion Models](https://github.com/VisualComputingInstitute/diffusion-e2e-ft).
Please ensure that the resulting depth `.npy` files are saved in the `depth_npy_{resolution}/` directory of the dataset. These files **must** be located in the same directory as the original images, and their filenames should match the original image filenames, with the suffix **`_pred.npy`** appended.

<details>
<summary><strong>Example layout for â€œfernâ€ scene (8Ã— downsampled)</strong></summary>

```bash
fern/
â”œâ”€â”€ images/
â”‚   â”œ IMG_4043.JPG
â”‚   â”œ IMG_4044.JPG
â”‚   â”œ IMG_4045.JPG
â”‚   â”” â€¦ other `.JPG` files
â”œâ”€â”€ sparse/
â”œâ”€â”€ dense/
â””â”€â”€ depth_npy_8/
    â”œ IMG_4043_pred.npy
    â”œ IMG_4044_pred.npy
    â”œ IMG_4045_pred.npy
    â”” â€¦ other `{image_name}_pred.npy` files
```

</details>

---

## ğŸ‹ï¸â€â™‚ï¸ Training

### ğŸ–¼ï¸ LLFF Dataset

To train on a single LLFF scene, use the following command:

```bash
python train.py -s ${DATASET_PATH} -m ${OUTPUT_PATH} --eval -r 8 --n_views {3 or 6 or 9}
```

### ğŸ–¼ï¸ MipNeRF-360 Dataset

To train on a single MipNeRF-360 scene, use the following command:

```bash
python train.py -s ${DATASET_PATH} -m ${OUTPUT_PATH} --eval -r 8 --n_views {12 or 24}
```

---

## ğŸ¥ Rendering

You can render a target scene using the following command:

### ğŸ–¼ï¸ LLFF Dataset

```bash
python render.py -s ${DATASET_PATH} -m ${MODEL_PATH} --eval -r 8 --iteration 10000
```

### ğŸ–¼ï¸ MipNeRF-360 Dataset

```bash
python render.py -s ${DATASET_PATH} -m ${MODEL_PATH} --eval -r 8 --iteration 10000
```

---

## ğŸ“Š Evaluation

You can evaluate the model performance using the following command:

### ğŸ–¼ï¸ LLFF Dataset

```bash
python metrics.py --model_paths ${MODEL_PATH}
```

### ğŸ–¼ï¸ MipNeRF-360 Dataset

```bash
python metrics.py --model_paths ${MODEL_PATH}
```
---
## ğŸ§ª Experimental Results

### âœ¨ Qualitative Results

![Qualitative Results](figures/Fig.svg)

---

## ğŸ“ Citation

If you find this work helpful, please consider citing:

```bibtex
@ARTICLE{ryu2025sss,
  author={Ryu, Gun and Kim, Wonjun},
  journal={IEEE Signal Processing Letters}, 
  title={Shape-Selective Splatting: Regularizing the Shape of Gaussian for Sparse-View Rendering}, 
  volume={32},
  pages={3172-3176},
  doi={10.1109/LSP.2025.3596225}
}

```

---

## ğŸ“« Contact

If you have any questions or issues, feel free to reach out:

- **Gun Ryu**: [fbrjs15@konkuk.ac.kr]  
